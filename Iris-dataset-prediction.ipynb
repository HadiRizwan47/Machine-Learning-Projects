{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "2AqfrEWhXHKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ðŸ“† Today I am gonna work on one of the most famous dataset **Iris dataset** ðŸ˜€. So we'll first take a look at the dataset, than will do KDE and based on the patterns we'll do Data Preprocessing. And finally in end we'll make models and test them. ðŸš€\n",
        "\n",
        "\n",
        " **About Dataset**\n",
        "\n",
        "\n",
        " its a pretty simple dataset with **5 columns ðŸ’Ž** and **150 rows ðŸ”º**\n",
        "\n",
        "\n",
        "\n",
        "1.   \tsepal length (cm) âš¡\n",
        "2.   sepal width (cm) âš¡\n",
        "1.   petal length (cm) âš¡\n",
        "2.   petal width (cm) âš¡\n",
        "5. target âš¡\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rlrq4zIGXPFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "vSOnJLcNVOi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading a built it dataset  and converting it to pandas DataFrame\n",
        "iris = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HEO5bYpyWcrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "ktukYyq1WhPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "b4so5Bk2XE7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "OjfcIsonXHM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking correlation\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "NslEGDhxXJU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique values\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "-fVHlB5KXLeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KDE**"
      ],
      "metadata": {
        "id": "wZffLkjQZvFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot\n",
        "sns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', data=df, hue='target')"
      ],
      "metadata": {
        "id": "As3FlMzhXOCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another scatter plot\n",
        "sns.scatterplot(x='petal length (cm)', y='petal width (cm)', data=df, hue='target')"
      ],
      "metadata": {
        "id": "dzXfvJ4vXyp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pair plot\n",
        "sns.pairplot(df, hue='target')"
      ],
      "metadata": {
        "id": "ftX5SOuBYAr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count plot\n",
        "sns.countplot(x='target', data=df, palette='Set2')"
      ],
      "metadata": {
        "id": "dB33DNjKYGHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot\n",
        "sns.boxplot(x='target', y='sepal length (cm)', data=df, palette='Set1')"
      ],
      "metadata": {
        "id": "rM40FL8KZG2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and again box plot\n",
        "sns.boxplot(x='target', y='sepal width (cm)', data=df, palette='Set1')"
      ],
      "metadata": {
        "id": "lXEzRwnXZJom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and again and again box plot\n",
        "sns.boxplot(x='target', y='petal length (cm)', data=df, palette='Set2')"
      ],
      "metadata": {
        "id": "egT5i75TZRbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and one last time BOX plot\n",
        "sns.boxplot(x='target', y='petal width (cm)', data=df, palette='Set2')"
      ],
      "metadata": {
        "id": "K_rbZF42ZWjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmap for cheacking correlation\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "ZN6zXiHYYKcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "9rQeCbDYZzRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining X and y\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']"
      ],
      "metadata": {
        "id": "uksxPQvgYr_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying train test splot\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SJSvc0OaZv-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the dataset\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ],
      "metadata": {
        "id": "hlZDiZnIbIPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled dataset\n",
        "X_train_scaled_df"
      ],
      "metadata": {
        "id": "-XcYD6lcaaaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "8VEb24sUnFAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training Logsitic Regression and applying GridSearchCV to find the best parameters\n",
        "log_reg = LogisticRegression()\n",
        "param_grid_lr = {\n",
        "    'C': [0.001, 0.01, 0.1, 10, 100],\n",
        "    'penalty':['l1', 'l2'],\n",
        "    'solver':['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_search_lr = GridSearchCV(log_reg, param_grid_lr, cv=5, scoring='accuracy')\n",
        "grid_search_lr.fit(X_train_scaled_df, y_train)\n",
        "\n",
        "print(\"Best parameters for Logistic Regression:\", grid_search_lr.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search_lr.best_score_)"
      ],
      "metadata": {
        "id": "XyXGVl9tbaay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training Decision Tree and applying GridSearchCV to find the best parameters\n",
        "dt = DecisionTreeClassifier()\n",
        "param_grid_dt = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion':['gini', 'entropy'],\n",
        "    'max_features':['auto', 'sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='accuracy')\n",
        "grid_search_dt.fit(X_train_scaled_df, y_train)\n",
        "\n",
        "print('Best parameters for Decision Tree:', grid_search_dt.best_params_)\n",
        "print('Best cross-validation accuracy:', grid_search_dt.best_score_)"
      ],
      "metadata": {
        "id": "K-_zgvM4ce7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training Random Forest and applying RandomizedSearchCV to find the best parameters\n",
        "rf = RandomForestClassifier()\n",
        "param_grid_rf = {\n",
        "    'n_estimators':[100, 200, 300],\n",
        "    'max_depth':[None, 5, 10, 15],\n",
        "    'min_samples_split':[2, 5, 10],\n",
        "    'min_samples_leaf':[1,2,4],\n",
        "    'max_features':['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap':[True, False]\n",
        "}\n",
        "\n",
        "rand_search_rf = RandomizedSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
        "rand_search_rf.fit(X_train_scaled_df, y_train)\n",
        "\n",
        "print('Best parameters Random Forest:', rand_search_rf.best_params_)\n",
        "print('Best cross-validation accuracy:', rand_search_rf.best_score_)"
      ],
      "metadata": {
        "id": "63MVNISdd3gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training SVM and applying GridSearchCV to find the best parameters\n",
        "svm = SVC()\n",
        "param_grid_svm = {\n",
        "    'C':[0.1, 1, 10, 100],\n",
        "    'kernel':['linear', 'rbf', 'poly','sigmoid'],\n",
        "    'gamma':['scale', 'rbf', 'poly', 'sigmoid'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='accuracy')\n",
        "grid_search_svm.fit(X_train_scaled_df, y_train)\n",
        "\n",
        "print('Best parameters for SVM:', grid_search_svm.best_params_)\n",
        "print('Best cross-validation accuracy:', grid_search_svm.best_score_)"
      ],
      "metadata": {
        "id": "nvX-v4pXc8oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3bb88a4"
      },
      "source": [
        "# **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the models\n",
        "\n",
        "# defining the best models\n",
        "best_log_reg = grid_search_lr.best_estimator_\n",
        "best_dt = grid_search_dt.best_estimator_\n",
        "best_rf = rand_search_rf.best_estimator_\n",
        "best_svm = grid_search_svm.best_estimator_\n",
        "\n",
        "# making predictions on test data\n",
        "y_pred_lr = best_log_reg.predict(X_test_scaled_df)\n",
        "y_pred_dt = best_dt.predict(X_test_scaled_df)\n",
        "y_pred_rf = best_rf.predict(X_test_scaled_df)\n",
        "y_pred_svm = best_svm.predict(X_test_scaled_df)\n",
        "\n",
        "# Results for Logistic Regression\n",
        "print(\"\\n---- Logistic Regression Evaluation ----\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
        "\n",
        "# Results for Decision Tree\n",
        "print(\"\\n--- Decision Tree Evaluation ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
        "\n",
        "# Results for Random Forest\n",
        "print(\"\\n--- Random Forest Evaluation ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "# Results for SVM\n",
        "print(\"\\n--- SVM Evaluation ---\")\n",
        "print(\"Accuracy:\\n\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "rmbaLFKujIUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "So as we can see the models are performing pretty well and giving full accuracy except SVM which is slightly worse than other models.\n",
        "Thanks for reading my notebook ðŸ˜¼"
      ],
      "metadata": {
        "id": "-3T7Sqz6oyeH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}